2024-08-06 10:21:10 | INFO | model_worker | args: Namespace(host='0.0.0.0', port=7801, worker_address='http://0.0.0.0:7801', controller_address='http://0.0.0.0:7800', model_path='/model_repos/CustomLLM/Qwen-14B-Chat', revision='main', device='cuda', gpus='0', num_gpus=1, max_gpu_memory=None, dtype='bfloat16', load_8bit=True, cpu_offloading=False, gptq_ckpt=None, gptq_wbits=16, gptq_groupsize=-1, gptq_act_order=False, awq_ckpt=None, awq_wbits=16, awq_groupsize=-1, enable_exllama=False, exllama_max_seq_len=4096, exllama_gpu_split=None, exllama_cache_8bit=False, enable_xft=False, xft_max_seq_len=4096, xft_dtype=None, model_names=None, conv_template='qwen-7b-chat', embed_in_truncate=False, limit_worker_concurrency=5, stream_interval=2, no_register=False, seed=None, debug=False, ssl=False)
2024-08-06 10:21:10 | INFO | model_worker | Loading the model ['Qwen-14B-Chat'] on worker ac86669b ...
2024-08-06 10:21:11 | ERROR | stderr | /usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4371: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead
2024-08-06 10:21:11 | ERROR | stderr |   warnings.warn(
2024-08-06 10:21:11 | ERROR | stderr |   0%|          | 0/15 [00:00<?, ?it/s]
2024-08-06 10:21:11 | ERROR | stderr |   7%|▋         | 1/15 [00:00<00:05,  2.48it/s]
2024-08-06 10:21:14 | ERROR | stderr |  13%|█▎        | 2/15 [00:02<00:21,  1.65s/it]
2024-08-06 10:21:15 | ERROR | stderr |  20%|██        | 3/15 [00:03<00:15,  1.28s/it]
2024-08-06 10:21:17 | ERROR | stderr |  27%|██▋       | 4/15 [00:05<00:16,  1.54s/it]
2024-08-06 10:21:22 | ERROR | stderr |  33%|███▎      | 5/15 [00:11<00:30,  3.03s/it]
2024-08-06 10:21:24 | ERROR | stderr |  40%|████      | 6/15 [00:13<00:23,  2.64s/it]
2024-08-06 10:21:26 | ERROR | stderr |  47%|████▋     | 7/15 [00:14<00:18,  2.32s/it]
2024-08-06 10:21:28 | ERROR | stderr |  53%|█████▎    | 8/15 [00:16<00:15,  2.14s/it]
2024-08-06 10:21:29 | ERROR | stderr |  60%|██████    | 9/15 [00:18<00:11,  1.99s/it]
2024-08-06 10:21:31 | ERROR | stderr |  67%|██████▋   | 10/15 [00:20<00:09,  1.89s/it]
2024-08-06 10:21:33 | ERROR | stderr |  73%|███████▎  | 11/15 [00:21<00:07,  1.83s/it]
2024-08-06 10:21:34 | ERROR | stderr |  80%|████████  | 12/15 [00:23<00:05,  1.78s/it]
2024-08-06 10:21:36 | ERROR | stderr |  87%|████████▋ | 13/15 [00:25<00:03,  1.74s/it]
2024-08-06 10:21:37 | ERROR | stderr |  93%|█████████▎| 14/15 [00:26<00:01,  1.71s/it]
2024-08-06 10:21:39 | ERROR | stderr | 100%|██████████| 15/15 [00:28<00:00,  1.71s/it]
2024-08-06 10:21:39 | ERROR | stderr | 100%|██████████| 15/15 [00:28<00:00,  1.89s/it]
2024-08-06 10:21:39 | ERROR | stderr | 
2024-08-06 10:21:39 | INFO | model_worker | Register to controller
2024-08-06 10:21:39 | ERROR | stderr | INFO:     Started server process [203]
2024-08-06 10:21:39 | ERROR | stderr | INFO:     Waiting for application startup.
2024-08-06 10:21:39 | ERROR | stderr | INFO:     Application startup complete.
2024-08-06 10:21:39 | ERROR | stderr | INFO:     Uvicorn running on http://0.0.0.0:7801 (Press CTRL+C to quit)
